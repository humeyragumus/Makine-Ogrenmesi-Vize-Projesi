{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import mean_squared_error,mean_absolute_error, r2_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hümeyra Gümüş - 21040301024 -Makine Öğrenmesi Vize Projesi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Pregnancies   Glucose  BloodPressure  SkinThickness   Insulin       BMI  \\\n",
      "0     0.352941  0.743719       0.590164       0.353535  0.000000  0.500745   \n",
      "1     0.058824  0.427136       0.540984       0.292929  0.000000  0.396423   \n",
      "2     0.470588  0.919598       0.524590       0.000000  0.000000  0.347243   \n",
      "3     0.058824  0.447236       0.540984       0.232323  0.111111  0.418778   \n",
      "\n",
      "   DiabetesPedigreeFunction       Age  Outcome  \n",
      "0                  0.234415  0.483333      1.0  \n",
      "1                  0.116567  0.166667      0.0  \n",
      "2                  0.253629  0.183333      1.0  \n",
      "3                  0.038002  0.000000      0.0  \n"
     ]
    }
   ],
   "source": [
    "normalized_data = (data - data.min()) / (data.max() - data.min())\n",
    "print(normalized_data.head(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Normalizasyon işlemi, her özelliğin (sütunun) minimum değerini çıkararak başlar ve ardından özelliğin aralığını (maksimum - minimum) bölerek özellikleri 0 ile 1 arasında ölçeklendirir. Bu sayede her bir özelliğin aralığı 0 ile 1 arasında bir ölçeklendirmeye tabi tutulur.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PCA için en yüksek iki öz değer:\n",
      "[0.26179749 0.21640127]\n",
      "        PC1       PC2  Outcome\n",
      "0  1.068503  1.234895        1\n",
      "1 -1.121683 -0.733852        0\n",
      "2 -0.396477  1.595876        1\n",
      "3 -1.115781 -1.271241        0\n",
      "4  2.359334 -2.184819        1\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "# Veriyi standartlaştıralım\n",
    "scaler = StandardScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "\n",
    "# PCA uygulayalım\n",
    "pca = PCA(n_components=2)\n",
    "x_pca = pca.fit_transform(x_scaled)\n",
    "\n",
    "# PCA için en yüksek iki öz değer\n",
    "print(\"PCA için en yüksek iki öz değer:\")\n",
    "print(pca.explained_variance_ratio_)\n",
    "\n",
    "# Oluşan yeni veri setini DataFrame'e dönüştürelim\n",
    "pca_df = pd.DataFrame(data = x_pca, columns = ['PC1', 'PC2'])\n",
    "\n",
    "# Oluşan PCA veri setini ve bağımlı değişkeni birleştirelim\n",
    "final_df = pd.concat([pca_df, y], axis = 1)\n",
    "\n",
    "print(final_df.head())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bağımlı değişken olan \"Outcome\" sütunu hariç tüm sütunları kullanarak bağımsız değişkenler veri çerçevesi (x) oluşturulur.\n",
    "\n",
    " Bağımlı değişken olan \"Outcome\" sütunu alınarak bağımlı değişken serisi (y) oluşturulur.\n",
    "\n",
    "\n",
    "Veriyi standartlaştırmak için StandardScaler nesnesi oluşturulur.\n",
    "\n",
    "Bağımsız değişkenler (x) standartlaştırılır ve x_scaled adında yeni bir dizi oluşturulur. Standartlaştırma, verinin ortalama ve standart sapmasına göre ölçeklendirilmesini sağlar.\n",
    "\n",
    "2 bileşenle PCA uygulaması için PCA nesnesi oluşturulur.\n",
    "\n",
    "Standartlaştırılmış bağımsız değişkenlere PCA uygulanarak iki bileşenli bir veri seti (x_pca) elde edilir.\n",
    "\n",
    "PCA için en yüksek iki öz değeri bildiren bir başlık yazdırılır.\n",
    "\n",
    "PCA ile elde edilen en yüksek iki öz değer ve bunların oransal katkıları yazdırılır. Bu, toplam varyansın ne kadarının iki ana bileşen tarafından açıklandığını gösterir.\n",
    "\n",
    "PCA ile elde edilen iki bileşenli veri (x_pca) bir DataFrame (pca_df) olarak dönüştürülür ve sütunlar 'PC1' ve 'PC2' olarak adlandırılır.\n",
    "\n",
    "PCA sonuçları (pca_df) ve bağımlı değişken (y) birleştirilir ve eksen 1 boyunca (axis=1) birleştirilmiş bir DataFrame (final_df) oluşturulur."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Katsayılar:\n",
      "                      Sütun   Katsayı\n",
      "0               Pregnancies  0.008994\n",
      "1                   Glucose  0.005742\n",
      "2             BloodPressure -0.001711\n",
      "3             SkinThickness -0.000253\n",
      "4                   Insulin -0.000126\n",
      "5                       BMI  0.016173\n",
      "6  DiabetesPedigreeFunction  0.072902\n",
      "7                       Age  0.006265\n",
      "\n",
      "Performans Metrikleri:\n",
      "R-kare (R²) Değeri: 0.2224076496611057\n",
      "Ortalama Mutlak Hata (MAE): 0.3534282433442794\n",
      "Ortalama Kare Hata (MSE): 0.17603335005142035\n",
      "Kök Ortalama Kare Hata (RMSE): 0.41956328491828304\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Çoklu doğrusal regresyon modelini oluşturalım ve eğitelim\n",
    "model = LinearRegression()\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "# Katsayıları raporlama\n",
    "coefficients = pd.DataFrame({'Sütun': x.columns, 'Katsayı': model.coef_})\n",
    "print(\"Katsayılar:\")\n",
    "print(coefficients)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "# Performans metriklerini hesaplayalım\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "mae = mean_absolute_error(y_test, y_pred)\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "\n",
    "print(\"\\nPerformans Metrikleri:\")\n",
    "print(\"R-kare (R²) Değeri:\", r2)\n",
    "print(\"Ortalama Mutlak Hata (MAE):\", mae)\n",
    "print(\"Ortalama Kare Hata (MSE):\", mse)\n",
    "print(\"Kök Ortalama Kare Hata (RMSE):\", rmse)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "train_test_split ile veri seti %70 eğitim ve %30 test olacak şekilde iki parçaya bölünür.\n",
    "\n",
    "LinearRegression sınıfını kullanarak bir çoklu doğrusal regresyon modeli oluşturulur ve x_train ve y_train kullanılarak model eğitilir.\n",
    "\n",
    "Eğitilen modelin katsayıları coefficients adlı bir DataFrame olarak raporlanır.\n",
    "\n",
    "Model x_test kullanılarak test verileri için tahminler (y_pred) yapar.\n",
    "\n",
    "Modelin performansı birkaç metrikle değerlendirilir:\n",
    "\n",
    "R-kare (R²): Modelin açıklanan varyans oranını ölçer.\n",
    "\n",
    "Ortalama Mutlak Hata (MAE): Tahmin hatalarının ortalama mutlak değerini ölçer.\n",
    "\n",
    "Ortalama Kare Hata (MSE): Tahmin hatalarının karelerinin ortalamasını ölçer.\n",
    "\n",
    "Kök Ortalama Kare Hata (RMSE): MSE'nin karekökünü hesaplayarak sonuçları daha anlamlı bir birimde ifade eder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk: 0.7359307359307359\n",
      "Sınıflandırma Raporu:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.79      0.80       151\n",
      "           1       0.62      0.62      0.62        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.71      0.71      0.71       231\n",
      "weighted avg       0.74      0.74      0.74       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "\n",
    "# Multinominal Lojistik Regresyon modelini eğitelim\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs', max_iter=1000)\n",
    "model.fit(x_train, y_train)\n",
    "\n",
    "y_pred = model.predict(x_test)\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Doğruluk:\", accuracy)\n",
    "\n",
    "print(\"Sınıflandırma Raporu:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LogisticRegression sınıfını kullanarak bir multinomial lojistik regresyon modeli (model) oluşturulur.\n",
    "\n",
    "Modelin performansı doğruluk (accuracy_score) ve sınıflandırma raporu (classification_report) ile değerlendirilir:\n",
    "\n",
    "accuracy_score fonksiyonu kullanılarak modelin doğruluk oranı hesaplanır.\n",
    "\n",
    "classification_report fonksiyonu kullanılarak modelin sınıflandırma performansı detaylı olarak raporlanır. Rapor, her bir sınıf için kesinlik (precision), duyarlılık (recall), ve F1 puanlarını içerir.\n",
    "\n",
    "Bu kod, test veri seti üzerindeki doğruluk ve sınıflandırma raporunu kullanarak modelin performansını değerlendirir. Bu, eğitilen modelin veri setini ne kadar iyi sınıflandırdığına dair bir fikir verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doğruluk: 0.7186147186147186\n",
      "\n",
      "Karışıklık Matrisi:\n",
      " [[111  40]\n",
      " [ 25  55]]\n",
      "\n",
      "Sınıflandırma Raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.74      0.77       151\n",
      "           1       0.58      0.69      0.63        80\n",
      "\n",
      "    accuracy                           0.72       231\n",
      "   macro avg       0.70      0.71      0.70       231\n",
      "weighted avg       0.73      0.72      0.72       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Karar ağacı modelini oluşturalım ve eğitelim\n",
    "clf = DecisionTreeClassifier()\n",
    "clf.fit(x_train, y_train)\n",
    "\n",
    "y_pred = clf.predict(x_test)\n",
    "\n",
    "# Performans metriklerini hesaplayalım\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_pred)\n",
    "class_report = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Doğruluk:\", accuracy)\n",
    "print(\"\\nKarışıklık Matrisi:\\n\", conf_matrix)\n",
    "print(\"\\nSınıflandırma Raporu:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "DecisionTreeClassifier sınıfını kullanarak bir karar ağacı modeli (clf) oluşturulur. Model, x_train ve y_train kullanılarak eğitilir.\n",
    "\n",
    "Confusion_matrix fonksiyonu kullanılarak modelin karışıklık matrisi hesaplanır. Bu matris, modelin tahminlerinin gerçek değerlerle nasıl karşılaştırıldığını gösterir.\n",
    "\n",
    "Bu kod, test veri seti üzerindeki doğruluk, karışıklık matrisi ve sınıflandırma raporunu kullanarak modelin performansını değerlendirir. Bu metrikler, eğitilen karar ağacı modelinin veri setini ne kadar iyi sınıflandırdığına dair bir fikir verir."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Eğitim seti doğruluğu: 0.7672253258845437\n",
      "Test seti doğruluğu: 0.7445887445887446\n",
      "\n",
      "Karışıklık Matrisi:\n",
      " [[119  32]\n",
      " [ 27  53]]\n",
      "\n",
      "Sınıflandırma Raporu:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.79      0.80       151\n",
      "           1       0.62      0.66      0.64        80\n",
      "\n",
      "    accuracy                           0.74       231\n",
      "   macro avg       0.72      0.73      0.72       231\n",
      "weighted avg       0.75      0.74      0.75       231\n",
      "\n"
     ]
    }
   ],
   "source": [
    "x = data.drop(\"Outcome\", axis=1)\n",
    "y = data[\"Outcome\"]\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# Naive Bayes sınıflandırıcısını oluşturalım ve eğitelim\n",
    "nb_classifier = GaussianNB()\n",
    "nb_classifier.fit(x_train, y_train)\n",
    "\n",
    "y_train_pred = nb_classifier.predict(x_train)\n",
    "y_test_pred = nb_classifier.predict(x_test)\n",
    "\n",
    "# Performans metriklerini hesaplayalım\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "conf_matrix = confusion_matrix(y_test, y_test_pred)\n",
    "class_report = classification_report(y_test, y_test_pred)\n",
    "\n",
    "print(\"Eğitim seti doğruluğu:\", train_accuracy)\n",
    "print(\"Test seti doğruluğu:\", test_accuracy)\n",
    "print(\"\\nKarışıklık Matrisi:\\n\", conf_matrix)\n",
    "print(\"\\nSınıflandırma Raporu:\\n\", class_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GaussianNB sınıfını kullanarak bir Naive Bayes sınıflandırıcısı (nb_classifier) oluşturulur. Model, x_train ve y_train kullanılarak eğitilir.\n",
    "\n",
    "Bu kod, Naive Bayes sınıflandırıcısı ile eğitim ve test veri setleri üzerinde modelin performansını değerlendirir. Performans metrikleri modelin doğruluğu, karışıklık matrisi ve sınıflandırma raporunu içerir. Bu metrikler, modelin veri setindeki sınıfları ne kadar iyi ayırt edebildiğine dair bilgi verir."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
